{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "# KFold, train_test_split, cross_val_score, RandomizedSearchCV, ...\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import *\n",
    "# mean_absolute_error, mean_squared_error, ...\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# notebook settings\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model-specific packages\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data ingestion, holdout split, and preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "above = '../../../'\n",
    "data = pd.read_pickle(above + 'd_PCmd.pkl')\n",
    "\n",
    "# Create holdout set and label X and Y columns.\n",
    "# RANDOM STATE is 5, don't change\n",
    "data_holdout = data.sample(frac = 0.2, random_state=5)\n",
    "X_holdout = data_holdout.drop('s_sale_price', axis=1)\n",
    "y_holdout = data_holdout['s_sale_price']\n",
    "\n",
    "# Remove holdout set from training data and label X and Y columns\n",
    "data_train = data.drop(data_holdout.index)\n",
    "X = data_train.drop('s_sale_price', axis=1)\n",
    "y = data_train['s_sale_price']\n",
    "\n",
    "# Scale features (important since we are doing regression)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_holdout = scaler.transform(X_holdout)\n",
    "# X_holdout = pd.DataFrame(scaler.fit_transform(X_holdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare subsampled data**\n",
    "\n",
    "From our learning curve analysis, we saw that our target X_train subsample size is 2^13 = 8192.\n",
    "In a 4-fold CV, where 25% would be set aside as test set, we need the total downsample size to then be 2^13/(.75) = 10.9k instances. (We can use the non-sampled instances for final validation as a holdout set, so no need to create a separate holdout set from the downsampled set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled = data.sample(n = 10900, random_state = 5)\n",
    "\n",
    "# separate downsampled set into X-Y for the CV.\n",
    "X_downsampled = downsampled.drop('s_sale_price', axis=1)\n",
    "y_downsampled = downsampled['s_sale_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGB Hyperparam tuning**\n",
    "\n",
    "\n",
    "reference:\n",
    "https://towardsdatascience.com/cross-validation-and-hyperparameter-tuning-how-to-optimise-your-machine-learning-model-13f005af9d7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100, 200, 300],\n",
       " 'learning_rate': [0.05, 0.1, 0.2, 0.3],\n",
       " 'subsample': [0.8, 0.9, 1.0]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Maximum number of levels in tree\n",
    "xgb_max_depth = [int(x) for x in np.linspace(2, 20, 10)]\n",
    "\n",
    "# Minimum number of instaces needed in each node\n",
    "xgb_min_child_weight = [int(x) for x in np.linspace(1, 10, 10)]\n",
    "\n",
    "# Tree construction algorithm used in XGBoost\n",
    "xgb_tree_method = ['auto', 'exact', 'approx', 'hist', 'gpu_hist']\n",
    "\n",
    "# Minimum loss reduction required to make further partition\n",
    "xgb_gamma = [int(x) for x in np.linspace(0, 0.5, 6)]\n",
    "\n",
    "# Learning objective used\n",
    "xgb_objective = ['reg:squarederror', 'reg:squaredlogerror']\n",
    "\n",
    "# Learning rate\n",
    "# xgb_learning_rate = [x for x in np.linspace(0.1, 0.6, 6)]\n",
    "xgb_learning_rate = [0.05, 0.1, 0.2, .3]\n",
    "\n",
    "# Number of trees to be used\n",
    "# xgb_n_estimators = [int(x) for x in np.linspace(200, 2000, 10)]\n",
    "xgb_n_estimators = [100, 200, 300]\n",
    "\n",
    "# Subsample\n",
    "xgb_subsample = [0.8, 0.9, 1.0]\n",
    "\n",
    "# Create the grid\n",
    "xgb_param_grid = {\n",
    "                  #'max_depth': xgb_max_depth,\n",
    "                  #'min_child_weight': xgb_min_child_weight,\n",
    "                  #'tree_method': xgb_tree_method,\n",
    "                  #'gamma': xgb_gamma,\n",
    "                  #'objective': xgb_objective,\n",
    "                  'n_estimators': xgb_n_estimators,\n",
    "                  'learning_rate': xgb_learning_rate,\n",
    "                  'subsample': xgb_subsample\n",
    "                 }\n",
    "\n",
    "display(xgb_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=None, reg_lambda=None,\n",
       "                                    scale_pos_weight=None, subsample=None,\n",
       "                                    tree_method=None, validate_parameters=None,\n",
       "                                    verbosity=None),\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.2, 0.3],\n",
       "                         'n_estimators': [100, 200, 300],\n",
       "                         'subsample': [0.8, 0.9, 1.0]},\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_regressor = XGBRegressor()\n",
    "\n",
    "gs = GridSearchCV(estimator = xgb_regressor,\n",
    "                  param_grid = xgb_param_grid,\n",
    "                  scoring = 'r2',\n",
    "                  cv = 4,\n",
    "                  verbose = 1)\n",
    "\n",
    "gs.fit(X_downsampled, y_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter:  {'learning_rate': 0.05, 'n_estimators': 100, 'subsample': 0.9}\n",
      "Best score:  0.6864510161913286\n",
      "Lowest Root Mean Square Error (RMSE):  0.8285233950778509\n",
      "[{'learning_rate': 0.05, 'n_estimators': 100, 'subsample': 0.8}, {'learning_rate': 0.05, 'n_estimators': 100, 'subsample': 0.9}, {'learning_rate': 0.05, 'n_estimators': 100, 'subsample': 1.0}, {'learning_rate': 0.05, 'n_estimators': 200, 'subsample': 0.8}, {'learning_rate': 0.05, 'n_estimators': 200, 'subsample': 0.9}, {'learning_rate': 0.05, 'n_estimators': 200, 'subsample': 1.0}, {'learning_rate': 0.05, 'n_estimators': 300, 'subsample': 0.8}, {'learning_rate': 0.05, 'n_estimators': 300, 'subsample': 0.9}, {'learning_rate': 0.05, 'n_estimators': 300, 'subsample': 1.0}, {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.8}, {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.9}, {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0}, {'learning_rate': 0.1, 'n_estimators': 200, 'subsample': 0.8}, {'learning_rate': 0.1, 'n_estimators': 200, 'subsample': 0.9}, {'learning_rate': 0.1, 'n_estimators': 200, 'subsample': 1.0}, {'learning_rate': 0.1, 'n_estimators': 300, 'subsample': 0.8}, {'learning_rate': 0.1, 'n_estimators': 300, 'subsample': 0.9}, {'learning_rate': 0.1, 'n_estimators': 300, 'subsample': 1.0}, {'learning_rate': 0.2, 'n_estimators': 100, 'subsample': 0.8}, {'learning_rate': 0.2, 'n_estimators': 100, 'subsample': 0.9}, {'learning_rate': 0.2, 'n_estimators': 100, 'subsample': 1.0}, {'learning_rate': 0.2, 'n_estimators': 200, 'subsample': 0.8}, {'learning_rate': 0.2, 'n_estimators': 200, 'subsample': 0.9}, {'learning_rate': 0.2, 'n_estimators': 200, 'subsample': 1.0}, {'learning_rate': 0.2, 'n_estimators': 300, 'subsample': 0.8}, {'learning_rate': 0.2, 'n_estimators': 300, 'subsample': 0.9}, {'learning_rate': 0.2, 'n_estimators': 300, 'subsample': 1.0}, {'learning_rate': 0.3, 'n_estimators': 100, 'subsample': 0.8}, {'learning_rate': 0.3, 'n_estimators': 100, 'subsample': 0.9}, {'learning_rate': 0.3, 'n_estimators': 100, 'subsample': 1.0}, {'learning_rate': 0.3, 'n_estimators': 200, 'subsample': 0.8}, {'learning_rate': 0.3, 'n_estimators': 200, 'subsample': 0.9}, {'learning_rate': 0.3, 'n_estimators': 200, 'subsample': 1.0}, {'learning_rate': 0.3, 'n_estimators': 300, 'subsample': 0.8}, {'learning_rate': 0.3, 'n_estimators': 300, 'subsample': 0.9}, {'learning_rate': 0.3, 'n_estimators': 300, 'subsample': 1.0}]\n",
      "[0.68380028 0.68645102 0.67989644 0.67945095 0.68213589 0.68041703\n",
      " 0.67778017 0.68033416 0.6806779  0.68139399 0.68303609 0.68146271\n",
      " 0.67704658 0.68095687 0.68077096 0.67565243 0.67890705 0.67953646\n",
      " 0.66178311 0.66500808 0.68108514 0.6599354  0.66193795 0.67763624\n",
      " 0.65912151 0.66094746 0.67727511 0.65465032 0.65009177 0.66005268\n",
      " 0.65232182 0.64800844 0.65827735 0.6517211  0.64755401 0.65769556]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter: \", gs.best_params_)\n",
    "print(\"Best score: \", gs.best_score_)\n",
    "print(\"Lowest Root Mean Square Error (RMSE): \", np.sqrt(np.abs(gs.best_score_)))\n",
    "\n",
    "print(gs.cv_results_['params'])\n",
    "print(gs.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed: 50.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter:  {'learning_rate': 0.05, 'n_estimators': 200, 'subsample': 0.9}\n",
      "Best score:  0.7212719313445051\n"
     ]
    }
   ],
   "source": [
    "# try again with the regular data, and see if the best params are different on the same range\n",
    "gs.fit(X, y)\n",
    "\n",
    "print(\"Best parameter: \", gs.best_params_)\n",
    "print(\"Best score: \", gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge Regressor Hyperparam Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ......................... alpha=0.001, score=0.500, total=   0.1s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ......................... alpha=0.001, score=0.483, total=   0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ......................... alpha=0.001, score=0.528, total=   0.0s\n",
      "[CV] alpha=0.001 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... alpha=0.001, score=0.385, total=   0.0s\n",
      "[CV] alpha=2.223111111111111 .........................................\n",
      "[CV] ............. alpha=2.223111111111111, score=0.502, total=   0.1s\n",
      "[CV] alpha=2.223111111111111 .........................................\n",
      "[CV] ............. alpha=2.223111111111111, score=0.484, total=   0.0s\n",
      "[CV] alpha=2.223111111111111 .........................................\n",
      "[CV] ............. alpha=2.223111111111111, score=0.529, total=   0.0s\n",
      "[CV] alpha=2.223111111111111 .........................................\n",
      "[CV] ............. alpha=2.223111111111111, score=0.394, total=   0.0s\n",
      "[CV] alpha=4.445222222222222 .........................................\n",
      "[CV] ............. alpha=4.445222222222222, score=0.504, total=   0.1s\n",
      "[CV] alpha=4.445222222222222 .........................................\n",
      "[CV] ............. alpha=4.445222222222222, score=0.485, total=   0.0s\n",
      "[CV] alpha=4.445222222222222 .........................................\n",
      "[CV] ............. alpha=4.445222222222222, score=0.529, total=   0.0s\n",
      "[CV] alpha=4.445222222222222 .........................................\n",
      "[CV] ............. alpha=4.445222222222222, score=0.400, total=   0.0s\n",
      "[CV] alpha=6.667333333333333 .........................................\n",
      "[CV] ............. alpha=6.667333333333333, score=0.505, total=   0.0s\n",
      "[CV] alpha=6.667333333333333 .........................................\n",
      "[CV] ............. alpha=6.667333333333333, score=0.486, total=   0.0s\n",
      "[CV] alpha=6.667333333333333 .........................................\n",
      "[CV] ............. alpha=6.667333333333333, score=0.529, total=   0.1s\n",
      "[CV] alpha=6.667333333333333 .........................................\n",
      "[CV] ............. alpha=6.667333333333333, score=0.404, total=   0.0s\n",
      "[CV] alpha=8.889444444444443 .........................................\n",
      "[CV] ............. alpha=8.889444444444443, score=0.506, total=   0.0s\n",
      "[CV] alpha=8.889444444444443 .........................................\n",
      "[CV] ............. alpha=8.889444444444443, score=0.487, total=   0.0s\n",
      "[CV] alpha=8.889444444444443 .........................................\n",
      "[CV] ............. alpha=8.889444444444443, score=0.530, total=   0.1s\n",
      "[CV] alpha=8.889444444444443 .........................................\n",
      "[CV] ............. alpha=8.889444444444443, score=0.407, total=   0.0s\n",
      "[CV] alpha=11.111555555555555 ........................................\n",
      "[CV] ............ alpha=11.111555555555555, score=0.506, total=   0.0s\n",
      "[CV] alpha=11.111555555555555 ........................................\n",
      "[CV] ............ alpha=11.111555555555555, score=0.488, total=   0.0s\n",
      "[CV] alpha=11.111555555555555 ........................................\n",
      "[CV] ............ alpha=11.111555555555555, score=0.530, total=   0.0s\n",
      "[CV] alpha=11.111555555555555 ........................................\n",
      "[CV] ............ alpha=11.111555555555555, score=0.409, total=   0.0s\n",
      "[CV] alpha=13.333666666666664 ........................................\n",
      "[CV] ............ alpha=13.333666666666664, score=0.507, total=   0.0s\n",
      "[CV] alpha=13.333666666666664 ........................................\n",
      "[CV] ............ alpha=13.333666666666664, score=0.488, total=   0.0s\n",
      "[CV] alpha=13.333666666666664 ........................................\n",
      "[CV] ............ alpha=13.333666666666664, score=0.530, total=   0.0s\n",
      "[CV] alpha=13.333666666666664 ........................................\n",
      "[CV] ............ alpha=13.333666666666664, score=0.411, total=   0.0s\n",
      "[CV] alpha=15.555777777777775 ........................................\n",
      "[CV] ............ alpha=15.555777777777775, score=0.507, total=   0.0s\n",
      "[CV] alpha=15.555777777777775 ........................................\n",
      "[CV] ............ alpha=15.555777777777775, score=0.489, total=   0.0s\n",
      "[CV] alpha=15.555777777777775 ........................................\n",
      "[CV] ............ alpha=15.555777777777775, score=0.530, total=   0.0s\n",
      "[CV] alpha=15.555777777777775 ........................................\n",
      "[CV] ............ alpha=15.555777777777775, score=0.412, total=   0.0s\n",
      "[CV] alpha=17.77788888888889 .........................................\n",
      "[CV] ............. alpha=17.77788888888889, score=0.508, total=   0.0s\n",
      "[CV] alpha=17.77788888888889 .........................................\n",
      "[CV] ............. alpha=17.77788888888889, score=0.489, total=   0.0s\n",
      "[CV] alpha=17.77788888888889 .........................................\n",
      "[CV] ............. alpha=17.77788888888889, score=0.530, total=   0.0s\n",
      "[CV] alpha=17.77788888888889 .........................................\n",
      "[CV] ............. alpha=17.77788888888889, score=0.413, total=   0.0s\n",
      "[CV] alpha=20.0 ......................................................\n",
      "[CV] .......................... alpha=20.0, score=0.508, total=   0.0s\n",
      "[CV] alpha=20.0 ......................................................\n",
      "[CV] .......................... alpha=20.0, score=0.489, total=   0.0s\n",
      "[CV] alpha=20.0 ......................................................\n",
      "[CV] .......................... alpha=20.0, score=0.530, total=   0.0s\n",
      "[CV] alpha=20.0 ......................................................\n",
      "[CV] .......................... alpha=20.0, score=0.414, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=Ridge(),\n",
       "             param_grid={'alpha': [0.001, 2.223111111111111, 4.445222222222222,\n",
       "                                   6.667333333333333, 8.889444444444443,\n",
       "                                   11.111555555555555, 13.333666666666664,\n",
       "                                   15.555777777777775, 17.77788888888889,\n",
       "                                   20.0]},\n",
       "             scoring='r2', verbose=3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_alphas = [x for x in np.linspace(0.001, 20, 10)]\n",
    "\n",
    "ridge_param_grid = {\n",
    "                  'alpha': ridge_alphas\n",
    "                 }\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "gs_ridge = GridSearchCV(estimator = ridge,\n",
    "                        param_grid = ridge_param_grid,\n",
    "                        scoring = 'r2',\n",
    "                        cv = 4,\n",
    "                        verbose = 3)\n",
    "\n",
    "gs_ridge.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter:  {'alpha': 20.0}\n",
      "Best score:  0.48541064914073195\n",
      "Lowest Root Mean Square Error (RMSE):  0.6967141803786772\n",
      "[{'alpha': 0.001}, {'alpha': 2.223111111111111}, {'alpha': 4.445222222222222}, {'alpha': 6.667333333333333}, {'alpha': 8.889444444444443}, {'alpha': 11.111555555555555}, {'alpha': 13.333666666666664}, {'alpha': 15.555777777777775}, {'alpha': 17.77788888888889}, {'alpha': 20.0}]\n",
      "[0.47394163 0.47741175 0.47961312 0.48114422 0.4822795  0.48316243\n",
      " 0.48387504 0.4844675  0.48497213 0.48541065]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter: \", gs_ridge.best_params_)\n",
    "print(\"Best score: \", gs_ridge.best_score_)\n",
    "print(\"Lowest Root Mean Square Error (RMSE): \", np.sqrt(np.abs(gs_ridge.best_score_)))\n",
    "\n",
    "print(gs_ridge.cv_results_['params'])\n",
    "print(gs_ridge.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ......................... alpha=0.001, score=0.677, total=   0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ......................... alpha=0.001, score=0.555, total=   0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ......................... alpha=0.001, score=0.464, total=   0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ......................... alpha=0.001, score=0.464, total=   0.0s\n",
      "[CV] alpha=2.223111111111111 .........................................\n",
      "[CV] ............. alpha=2.223111111111111, score=0.677, total=   0.0s\n",
      "[CV] alpha=2.223111111111111 .........................................\n",
      "[CV] ............. alpha=2.223111111111111, score=0.555, total=   0.0s\n",
      "[CV] alpha=2.223111111111111 .........................................\n",
      "[CV] ............. alpha=2.223111111111111, score=0.464, total=   0.0s\n",
      "[CV] alpha=2.223111111111111 .........................................\n",
      "[CV] ............. alpha=2.223111111111111, score=0.464, total=   0.0s\n",
      "[CV] alpha=4.445222222222222 .........................................\n",
      "[CV] ............. alpha=4.445222222222222, score=0.677, total=   0.0s\n",
      "[CV] alpha=4.445222222222222 .........................................\n",
      "[CV] ............. alpha=4.445222222222222, score=0.555, total=   0.0s\n",
      "[CV] alpha=4.445222222222222 .........................................\n",
      "[CV] ............. alpha=4.445222222222222, score=0.464, total=   0.0s\n",
      "[CV] alpha=4.445222222222222 .........................................\n",
      "[CV] ............. alpha=4.445222222222222, score=0.464, total=   0.0s\n",
      "[CV] alpha=6.667333333333333 .........................................\n",
      "[CV] ............. alpha=6.667333333333333, score=0.677, total=   0.0s\n",
      "[CV] alpha=6.667333333333333 .........................................\n",
      "[CV] ............. alpha=6.667333333333333, score=0.555, total=   0.0s\n",
      "[CV] alpha=6.667333333333333 .........................................\n",
      "[CV] ............. alpha=6.667333333333333, score=0.465, total=   0.0s\n",
      "[CV] alpha=6.667333333333333 .........................................\n",
      "[CV] ............. alpha=6.667333333333333, score=0.464, total=   0.0s\n",
      "[CV] alpha=8.889444444444443 .........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. alpha=8.889444444444443, score=0.677, total=   0.0s\n",
      "[CV] alpha=8.889444444444443 .........................................\n",
      "[CV] ............. alpha=8.889444444444443, score=0.555, total=   0.0s\n",
      "[CV] alpha=8.889444444444443 .........................................\n",
      "[CV] ............. alpha=8.889444444444443, score=0.465, total=   0.0s\n",
      "[CV] alpha=8.889444444444443 .........................................\n",
      "[CV] ............. alpha=8.889444444444443, score=0.464, total=   0.0s\n",
      "[CV] alpha=11.111555555555555 ........................................\n",
      "[CV] ............ alpha=11.111555555555555, score=0.677, total=   0.0s\n",
      "[CV] alpha=11.111555555555555 ........................................\n",
      "[CV] ............ alpha=11.111555555555555, score=0.555, total=   0.0s\n",
      "[CV] alpha=11.111555555555555 ........................................\n",
      "[CV] ............ alpha=11.111555555555555, score=0.465, total=   0.0s\n",
      "[CV] alpha=11.111555555555555 ........................................\n",
      "[CV] ............ alpha=11.111555555555555, score=0.464, total=   0.0s\n",
      "[CV] alpha=13.333666666666664 ........................................\n",
      "[CV] ............ alpha=13.333666666666664, score=0.677, total=   0.0s\n",
      "[CV] alpha=13.333666666666664 ........................................\n",
      "[CV] ............ alpha=13.333666666666664, score=0.555, total=   0.0s\n",
      "[CV] alpha=13.333666666666664 ........................................\n",
      "[CV] ............ alpha=13.333666666666664, score=0.465, total=   0.0s\n",
      "[CV] alpha=13.333666666666664 ........................................\n",
      "[CV] ............ alpha=13.333666666666664, score=0.464, total=   0.0s\n",
      "[CV] alpha=15.555777777777775 ........................................\n",
      "[CV] ............ alpha=15.555777777777775, score=0.677, total=   0.0s\n",
      "[CV] alpha=15.555777777777775 ........................................\n",
      "[CV] ............ alpha=15.555777777777775, score=0.555, total=   0.0s\n",
      "[CV] alpha=15.555777777777775 ........................................\n",
      "[CV] ............ alpha=15.555777777777775, score=0.465, total=   0.0s\n",
      "[CV] alpha=15.555777777777775 ........................................\n",
      "[CV] ............ alpha=15.555777777777775, score=0.464, total=   0.0s\n",
      "[CV] alpha=17.77788888888889 .........................................\n",
      "[CV] ............. alpha=17.77788888888889, score=0.677, total=   0.0s\n",
      "[CV] alpha=17.77788888888889 .........................................\n",
      "[CV] ............. alpha=17.77788888888889, score=0.555, total=   0.0s\n",
      "[CV] alpha=17.77788888888889 .........................................\n",
      "[CV] ............. alpha=17.77788888888889, score=0.465, total=   0.0s\n",
      "[CV] alpha=17.77788888888889 .........................................\n",
      "[CV] ............. alpha=17.77788888888889, score=0.464, total=   0.0s\n",
      "[CV] alpha=20.0 ......................................................\n",
      "[CV] .......................... alpha=20.0, score=0.677, total=   0.0s\n",
      "[CV] alpha=20.0 ......................................................\n",
      "[CV] .......................... alpha=20.0, score=0.555, total=   0.0s\n",
      "[CV] alpha=20.0 ......................................................\n",
      "[CV] .......................... alpha=20.0, score=0.465, total=   0.0s\n",
      "[CV] alpha=20.0 ......................................................\n",
      "[CV] .......................... alpha=20.0, score=0.464, total=   0.0s\n",
      "Best parameter:  {'learning_rate': 0.05, 'n_estimators': 200, 'subsample': 0.9}\n",
      "Best score:  0.7212719313445051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "# try again with the subsampled data, and see if the best params are different on the same range\n",
    "gs_ridge.fit(X_downsampled, y_downsampled)\n",
    "\n",
    "print(\"Best parameter: \", gs.best_params_)\n",
    "print(\"Best score: \", gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Model Eval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=200, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.9,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Ridge Regressor with tuned hyperparams\n",
    "ridge_tuned = Ridge(alpha = 20)\n",
    "\n",
    "# Create XGBRegressor with tuned hyperparams\n",
    "# {'learning_rate': 0.05, 'n_estimators': 200, 'subsample': 0.9}\n",
    "xgb_tuned = XGBRegressor(n_estimators = 200,\n",
    "                         learning_rate = 0.05,\n",
    "                         subsample = 0.9)\n",
    "\n",
    "# Train the models using 80% of the original data\n",
    "ridge_tuned.fit(X, y)\n",
    "xgb_tuned.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that compares all final models\n",
    "def final_comparison(models, test_features, test_labels):\n",
    "    scores = pd.DataFrame()\n",
    "    \n",
    "    for model in models:\n",
    "        predictions = model.predict(test_features)\n",
    "        \n",
    "        mae = mean_absolute_error(test_labels, predictions)\n",
    "        mse = mean_squared_error(test_labels, predictions) \n",
    "        r2 = r2_score(test_labels, predictions)\n",
    "        errors = abs(predictions - test_labels)\n",
    "        mape = 100 * np.mean(errors / test_labels)\n",
    "        accuracy = 100 - mape\n",
    "        \n",
    "        scores[str(model)] = [\"%.3f\" % mae, \"%.3f\" % mse, \"%.3f\" % r2, \"%.3f\" % accuracy]\n",
    "    \n",
    "    scores.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2', 'Accuracy']\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the comparison function with the final optimized models\n",
    "final_scores = final_comparison([ridge_tuned, xgb_tuned], X_holdout, y_holdout)\n",
    "\n",
    "# Adjust the column headers\n",
    "final_scores.columns  = ['Ridge Regressor', 'Extreme Gradient Boosting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge Regressor</th>\n",
       "      <th>Extreme Gradient Boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>273626.825</td>\n",
       "      <td>179484.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>780822377030.766</td>\n",
       "      <td>387433500723.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R^2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>58.068</td>\n",
       "      <td>69.583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Ridge Regressor Extreme Gradient Boosting\n",
       "Mean Absolute Error        273626.825                179484.760\n",
       "Mean Squared Error   780822377030.766          387433500723.288\n",
       "R^2                             0.530                     0.767\n",
       "Accuracy                       58.068                    69.583"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
